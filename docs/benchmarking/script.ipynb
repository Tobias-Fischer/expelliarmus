{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from expelliarmus import Wizard\n",
    "import pathlib\n",
    "import h5py\n",
    "import numpy as np\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPEAT= 10\n",
    "\n",
    "files = (\"potter/spinner.dat\", \"potter/spinner.raw\", \"potter/pedestrians.raw\")\n",
    "encodings = (\"dat\", \"evt2\", \"evt3\")\n",
    "\n",
    "for f, encoding in zip(files, encodings):\n",
    "    print(\"=\"*50)\n",
    "    wizard = Wizard(encoding=encoding)\n",
    "    fpath = pathlib.Path(f)\n",
    "    h5_fpath = pathlib.Path(f\"./ref_HDF5_{encoding.upper()}.hdf5\")\n",
    "    h5_LZF_fpath = pathlib.Path(f\"./ref_HDF5_LZF_{encoding.upper()}.hdf5\")\n",
    "    np_fpath = pathlib.Path(f\"./ref_np_{encoding.upper()}.npy\")\n",
    "\n",
    "    arr = wizard.read(fpath)\n",
    "\n",
    "    # HDF5 \n",
    "    h5_fp = h5py.File(h5_fpath, \"w\")\n",
    "    arr_h5 = h5_fp.create_dataset(\"arr\", arr.shape, arr.dtype)\n",
    "    arr_h5[:] = wizard.read(fpath)\n",
    "    h5_fp.close()\n",
    "\n",
    "    # HDF5 LZF\n",
    "    h5_LZF_fp = h5py.File(h5_LZF_fpath, \"w\")\n",
    "    arr_h5_lzf = h5_LZF_fp.create_dataset(\"arr\", arr.shape, arr.dtype, compression=\"lzf\")\n",
    "    arr_h5_lzf[:] = wizard.read(fpath)\n",
    "    h5_LZF_fp.close()\n",
    "    \n",
    "    # NumPy\n",
    "    np.save(np_fpath, arr, allow_pickle=False)\n",
    "\n",
    "    avg_time_ours = timeit.repeat(lambda: wizard.read(fpath), number=1, repeat=REPEAT) \n",
    "    avg_time_ours = sum(avg_time_ours) / len(avg_time_ours)\n",
    "    print(f\"{encoding.upper()} ({fpath.stat().st_size//(1024*1024)}MB) avg_time = {avg_time_ours:.3f} s.\")\n",
    "\n",
    "    h5_fp = h5py.File(h5_fpath)\n",
    "    avg_time = timeit.repeat(lambda: h5_fp[\"arr\"][:], number=1, repeat=REPEAT) \n",
    "    avg_time = sum(avg_time) / len(avg_time)\n",
    "    print(f\"HDF5 {encoding.upper()} ({h5_fpath.stat().st_size//(1024*1024)}MB) avg_time = {avg_time:.3f} s ({'+' if avg_time_ours<avg_time else '-'}{((1-avg_time_ours/avg_time) if avg_time_ours<avg_time else (1-avg_time/avg_time_ours))*100:.2f}%).\")\n",
    "    h5_fp.close()\n",
    "\n",
    "    h5_LZF_fp = h5py.File(h5_LZF_fpath)\n",
    "    avg_time = timeit.repeat(lambda: h5_LZF_fp[\"arr\"][:], number=1, repeat=REPEAT) \n",
    "    avg_time = sum(avg_time) / len(avg_time)\n",
    "    print(f\"HDF5 LZF {encoding.upper()} ({h5_LZF_fpath.stat().st_size//(1024*1024)}MB) avg_time = {avg_time:.3f} s ({'+' if avg_time_ours<avg_time else '-'}{((1-avg_time_ours/avg_time) if avg_time_ours<avg_time else (1-avg_time/avg_time_ours))*100:.2f}%).\")\n",
    "    h5_LZF_fp.close()\n",
    "\n",
    "    avg_time = timeit.repeat(lambda: np.load(np_fpath), number=1, repeat=REPEAT) \n",
    "    avg_time = sum(avg_time) / len(avg_time)\n",
    "    print(f\"NumPy {encoding.upper()} ({np_fpath.stat().st_size//(1024*1024)}MB) avg_time = {avg_time:.3f} s ({'+' if avg_time_ours<avg_time else '-'}{((1-avg_time_ours/avg_time) if avg_time_ours<avg_time else (1-avg_time/avg_time_ours))*100:.2f}%).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65b6f4b806bbaf5b54d6ccaa27abf7e5307b1f0e4411e9da36d5256169cebdd7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
